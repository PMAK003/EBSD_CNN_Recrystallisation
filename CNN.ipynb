{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ce1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from skimage.morphology import remove_small_objects\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score\n",
    ")\n",
    "matplotlib.use('Agg')  # headless-safe\n",
    "\n",
    "# --------------------- CTF LOADING --------------------- \n",
    "def load_ctf_file(path, mad_thresh, bands_thresh, min_region_size):\n",
    "    \"\"\"\n",
    "    Load .ctf → (feature H×W×3, target H×W) using:\n",
    "      target = (MAD < mad_thresh) & (Bands > bands_thresh),\n",
    "      small regions < min_region_size removed.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=r\"\\s+|\\t\", comment='[', engine='python')\n",
    "    expected = {'X','Y','Euler1','Euler2','Euler3','Bands','MAD'}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        print(f\"[{os.path.basename(path)}] Missing columns: {missing}\")\n",
    "        return None\n",
    "\n",
    "    # Keep only indexed points\n",
    "    df = df[df['Bands'] > 0]\n",
    "\n",
    "    # Build raw mask\n",
    "    df['recryst'] = ((df['MAD'] < mad_thresh) &\n",
    "                     (df['Bands'] > bands_thresh)).astype(np.uint8)\n",
    "\n",
    "    frac = df['recryst'].mean() * 100\n",
    "    print(f\"[{os.path.basename(path)}] {frac:.1f}% recrystallized \"\n",
    "          f\"(MAD<{mad_thresh}, Bands>{bands_thresh})\")\n",
    "\n",
    "\n",
    "    # Construct grids\n",
    "    x_vals = np.sort(df['X'].unique())\n",
    "    y_vals = np.sort(df['Y'].unique())\n",
    "\n",
    "    # Pivot each Euler angle\n",
    "    eulers = {}\n",
    "    for col in ['Euler1','Euler2','Euler3']:\n",
    "        grid = df.pivot(index='Y', columns='X', values=col)\n",
    "        grid = grid.reindex(index=y_vals, columns=x_vals)\n",
    "        grid = grid.interpolate(axis=1, limit_direction='both')\n",
    "        grid = grid.interpolate(axis=0, limit_direction='both')\n",
    "        grid = grid.ffill(axis=1).bfill(axis=1)\n",
    "        grid = grid.ffill(axis=0).bfill(axis=0)\n",
    "        eulers[col] = grid.values\n",
    "\n",
    "    # Pivot the mask and clean it with skimage\n",
    "    mask_df = df.pivot(index='Y', columns='X', values='recryst')\n",
    "    mask_df = mask_df.reindex(index=y_vals, columns=x_vals).fillna(0)\n",
    "    mask_arr = mask_df.values.astype(bool)\n",
    "    mask_clean = remove_small_objects(mask_arr, min_size=min_region_size).astype(np.uint8)\n",
    "\n",
    "    # Stack features\n",
    "    feature = np.stack([eulers['Euler1'], eulers['Euler2'], eulers['Euler3']], axis=2)\n",
    "    target  = mask_clean\n",
    "\n",
    "    return feature, target\n",
    "\n",
    "def load_all_ctf_data(folder, mad_thresh=0.5, bands_thresh=8, min_region_size=100):\n",
    "    maps = []\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.lower().endswith('.ctf'):\n",
    "            data = load_ctf_file(\n",
    "                os.path.join(folder, fname),\n",
    "                mad_thresh, bands_thresh, min_region_size\n",
    "            )\n",
    "            if data is not None:\n",
    "                maps.append(data)\n",
    "    print(f\"Loaded {len(maps)} maps from '{folder}'\")\n",
    "    return maps\n",
    "\n",
    "# ------------------ PATCH DATASET -----------------------\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, maps, patch_size=64, patches_per_map=300):\n",
    "        self.patches = []\n",
    "        for feat, mask in maps:\n",
    "            H, W, _ = feat.shape\n",
    "            if H < patch_size or W < patch_size:\n",
    "                continue\n",
    "            for _ in range(patches_per_map):\n",
    "                x = np.random.randint(0, W - patch_size + 1)\n",
    "                y = np.random.randint(0, H - patch_size + 1)\n",
    "                self.patches.append((\n",
    "                    feat[y:y+patch_size, x:x+patch_size],\n",
    "                    mask[y:y+patch_size, x:x+patch_size]\n",
    "                ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f, m = self.patches[idx]\n",
    "        return (\n",
    "            torch.tensor(f, dtype=torch.float32).permute(2,0,1),\n",
    "            torch.tensor(m, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "# ------------------- DOUBLE U-NET -----------------------\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.enc1 = UNetBlock(in_c,64)\n",
    "        self.enc2 = UNetBlock(64,128)\n",
    "        self.enc3 = UNetBlock(128,256)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up2  = nn.ConvTranspose2d(256,128,2,stride=2)\n",
    "        self.up1  = nn.ConvTranspose2d(128,64,2,stride=2)\n",
    "        self.dec2 = UNetBlock(256,128)\n",
    "        self.dec1 = UNetBlock(128,64)\n",
    "        self.out  = nn.Conv2d(64,out_c,1)\n",
    "\n",
    "    def _crop(self, enc, dec):\n",
    "        _,_,h_e,w_e = enc.size()\n",
    "        _,_,h_d,w_d = dec.size()\n",
    "        ch, cw = (h_e-h_d)//2, (w_e-w_d)//2\n",
    "        return enc[:,:,ch:ch+h_d,cw:cw+w_d]\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        u2 = self.up2(e3); c2 = self._crop(e2,u2)\n",
    "        d2 = self.dec2(torch.cat([u2,c2], dim=1))\n",
    "        u1 = self.up1(d2); c1 = self._crop(e1,u1)\n",
    "        d1 = self.dec1(torch.cat([u1,c1], dim=1))\n",
    "        return self.out(d1)\n",
    "\n",
    "class DoubleUNet(nn.Module):\n",
    "    def __init__(self, in_ch, out_c):\n",
    "        super().__init__()\n",
    "        self.u1 = UNet(in_ch, out_c)\n",
    "        self.u2 = UNet(in_ch + out_c, out_c)\n",
    "    def forward(self, x):\n",
    "        o1 = self.u1(x)\n",
    "        s  = torch.softmax(o1, dim=1)\n",
    "        h  = min(x.size(2), s.size(2))\n",
    "        w  = min(x.size(3), s.size(3))\n",
    "        xc = x[:,:,:h,:w]\n",
    "        sc = s[:,:,:h,:w]\n",
    "        return self.u2(torch.cat([xc, sc],dim=1))\n",
    "\n",
    "# ------------------ METRICS & PLOTTING --------------------\n",
    "def evaluate_model(model, loader, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    all_p, all_t, all_pr = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            prob = torch.softmax(out,1)[:,1,:,:].reshape(-1).cpu().numpy()\n",
    "            p    = torch.argmax(out,1).reshape(-1).cpu().numpy()\n",
    "            t    = yb.reshape(-1).cpu().numpy()\n",
    "            all_pr.append(prob); all_p.append(p); all_t.append(t)\n",
    "\n",
    "    y_prob = np.concatenate(all_pr)\n",
    "    y_pred = np.concatenate(all_p)\n",
    "    y_true = np.concatenate(all_t)\n",
    "\n",
    "    return {\n",
    "        'accuracy' : accuracy_score(y_true,y_pred),\n",
    "        'precision': precision_score(y_true,y_pred,average='binary',zero_division=0),\n",
    "        'recall'   : recall_score(y_true,y_pred,average='binary',zero_division=0),\n",
    "        'f1'       : f1_score(y_true,y_pred,average='binary',zero_division=0),\n",
    "        'roc_auc'  : roc_auc_score(y_true,y_prob)\n",
    "    }\n",
    "\n",
    "def plot_history(hist, save_path='training_metrics.png'):\n",
    "    epochs = range(1,len(hist['loss'])+1)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    keys = ['loss','accuracy','precision','recall','f1','roc_auc']\n",
    "    for i,k in enumerate(keys,1):\n",
    "        plt.subplot(3,2,i)\n",
    "        plt.plot(epochs, hist[k], '-o')\n",
    "        plt.title(k.replace('_',' ').title())\n",
    "        plt.ylim(0,1 if k!='loss' else None)\n",
    "        plt.grid()\n",
    "    plt.tight_layout(); plt.savefig(save_path); plt.close()\n",
    "\n",
    "# -------------------- TRAINING --------------------------\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    hist = {k:[] for k in ('loss','accuracy','precision','recall','f1','roc_auc')}\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); running=0.0\n",
    "        for xb,yb in train_loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out,yb)\n",
    "            loss.backward(); opt.step()\n",
    "            running += loss.item()\n",
    "        train_loss = running/len(train_loader)\n",
    "        hist['loss'].append(train_loss)\n",
    "\n",
    "        metrics = evaluate_model(model, val_loader, device)\n",
    "        for k,v in metrics.items():\n",
    "            hist[k].append(v)\n",
    "\n",
    "        print(f\"Epoch {ep}/{epochs} — loss {train_loss:.4f}, \"\n",
    "              f\"acc {metrics['accuracy']:.4f}, prec {metrics['precision']:.4f}, \"\n",
    "              f\"rec {metrics['recall']:.4f}, f1 {metrics['f1']:.4f}, auc {metrics['roc_auc']:.4f}\")\n",
    "\n",
    "    plot_history(hist)\n",
    "    return hist\n",
    "\n",
    "# -------------------- INFERENCE VIS ----------------------\n",
    "def visualize_predictions(model, maps, output_dir='output_images'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        for i,(fm,_) in enumerate(maps):\n",
    "            H,W,_ = fm.shape\n",
    "            x = torch.tensor(fm, dtype=torch.float32).permute(2,0,1).unsqueeze(0).to(device)\n",
    "            raw = model(x)\n",
    "            h,w = min(H, raw.size(2)), min(W, raw.size(3))\n",
    "            pred = torch.argmax(raw[:,:,:h,:w].squeeze(), dim=0).cpu().numpy()\n",
    "            mask = remove_small_objects(pred.astype(bool), min_size=64).astype(np.uint8)\n",
    "            color = np.zeros((h,w,3), dtype=np.uint8)\n",
    "            color[mask==1] = [0,0,255]; color[mask==0] = [255,0,0]\n",
    "            plt.imsave(os.path.join(output_dir, f'pred_{i}.png'), color)\n",
    "\n",
    "\n",
    "# -------------------- MAIN ------------------------------\n",
    "if __name__=='__main__':\n",
    "    maps = load_all_ctf_data('CTF',\n",
    "                             mad_thresh=0.5,\n",
    "                             bands_thresh=8,\n",
    "                             min_region_size=0)\n",
    "\n",
    "    split = int(0.8*len(maps))\n",
    "    train_maps, val_maps = maps[:split], maps[split:]\n",
    "\n",
    "    train_loader = DataLoader(PatchDataset(train_maps), batch_size=16, shuffle=True)\n",
    "    val_loader   = DataLoader(PatchDataset(val_maps, patches_per_map=100),\n",
    "                              batch_size=16, shuffle=False)\n",
    "\n",
    "    model   = DoubleUNet(3,2)\n",
    "    history = train_model(model, train_loader, val_loader, epochs=10, lr=1e-3)\n",
    "\n",
    "    print(\"Final Train Metrics:\", evaluate_model(model, train_loader))\n",
    "    print(\"Final  Val Metrics:\", evaluate_model(model, val_loader))\n",
    "\n",
    "    visualize_predictions(model, maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e9f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the prediction image\n",
    "image_path = 'output_images/pred_0.png'\n",
    "image = Image.open(image_path)\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Define the colors for recrystallized (blue) and deformed (red)\n",
    "recrystallized_color = [0, 0, 255]  # Blue\n",
    "deformed_color = [255, 0, 0]        # Red\n",
    "\n",
    "# Count the pixels for each category\n",
    "total_pixels = image_array.shape[0] * image_array.shape[1]\n",
    "# Ensure the comparison includes the alpha channel\n",
    "recrystallized_pixels = np.sum(np.all(image_array[:, :, :3] == recrystallized_color, axis=-1))\n",
    "deformed_pixels = np.sum(np.all(image_array[:, :, :3] == deformed_color, axis=-1))\n",
    "\n",
    "# Calculate percentages\n",
    "recrystallized_percentage = (recrystallized_pixels / total_pixels) * 100\n",
    "deformed_percentage = (deformed_pixels / total_pixels) * 100\n",
    "\n",
    "print(f\"Recrystallized: {recrystallized_percentage:.2f}%\")\n",
    "print(f\"Deformed: {deformed_percentage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
